If there is no provided prompt in the paper, use the following prompts.
- **Prompt (short)**: "Provide a one-sentence caption for the provided image."
- **Prompt (long)**: "Describe the image in detail."

## ✅BLIP-2
- **Model**: [BLIP-2 OPT-2.7b](https://huggingface.co/Salesforce/blip2-opt-2.7b)
- **Paper**: [BLIP-2 Paper](https://arxiv.org/pdf/2301.12597)

## ✅InstructBLIP
- **Model**: [InstructBLIP Vicuna-7B](https://huggingface.co/Salesforce/instructblip-vicuna-7b)
- **Paper**: [InstructBLIP Paper](https://arxiv.org/pdf/2305.06500)
- **Prompt (short)**: "A short image description:"
- **Prompt (long)**: Not Found

## ✅Qwen-VL
- **Model**: [Qwen-VL](https://huggingface.co/Qwen/Qwen-VL-Chat)
- **Paper**: [Qwen-VL Paper](https://arxiv.org/pdf/2308.12966)
- **Prompt (short)**: "Describe the image in English:"
- **Prompt (long)**: Not Found

## MiniGPT-4
- **Model**: [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)
- **Paper**: [MiniGPT-4 Paper](https://arxiv.org/pdf/2304.10592)
- **Prompt (short)**: Not Found
- **Prompt (long)**: "Describe this image in detail."

## LLaVA
- **Model**: [LLaVA](https://github.com/haotian-liu/LLaVA)
- **Paper**: [LLaVA Paper](https://arxiv.org/pdf/2304.08485)
- **Prompt (short)**: "Describe the image concisely."
- **Prompt (long)**: "Describe the following image in detail."

## ✅LLaVA 1.5
- **Model**: [LLaVA 1.5](https://huggingface.co/liuhaotian/llava-v1.5-7b)
- **Paper**: [LLaVA 1.5 Paper](https://arxiv.org/pdf/2310.03744)
- **Prompt (short)**: "Provide a one-sentence caption for the provided image."
- **Prompt (long)**: Not Found

## mPLUG-Owl-7B
- **Model**: [mPLUG-Owl-7B](https://huggingface.co/MAGAer13/mplug-owl-llama-7b)
- **Paper**: [mPLUG-Owl-7B Paper](https://arxiv.org/pdf/2304.14178)
- **Prompt (short)**: "USER: <|image|>Provide a one-sentence caption for the provided image. ASSISTANT: "
- **Prompt (long)**: "<|image|>Describe the image."

## mPLUG-Owl2-7B
- **Model**: [mPLUG-Owl2-7B](https://huggingface.co/MAGAer13/mplug-owl2-llama2-7b)
- **Paper**: [mPLUG-Owl2-7B Paper](https://arxiv.org/pdf/2311.04257)
- **Prompt (short)**: "USER: Provide a one-sentence caption for the provided image. ASSISTANT: "
- **Prompt (long)**: "Describe the image."

## Multimodal-GPT
- **Model**: [Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT)
- **Paper**: [Multimodal-GPT Paper](https://arxiv.org/pdf/2305.04790)
- **Prompt (short)**: Not Found
- **Prompt (long)**: "Can you describe the image?"

## Otter
- **Model**: [Otter](https://github.com/Luodian/Otter?tab=readme-ov-file), [Otter Model](https://huggingface.co/luodian/OTTER-Image-MPT7B)
- **Paper**: [Otter Paper](https://arxiv.org/pdf/2305.03726)
- **Prompt (short)**: Not Found
- **Prompt (long)**: f"\<image>User: What does the image describe? GPT:\<answer>"
